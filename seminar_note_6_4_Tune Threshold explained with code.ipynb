{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "minute-electronics",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))\n",
    "import warnings\n",
    "warnings.filterwarnings(action='ignore') \n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ff10c41",
   "metadata": {},
   "source": [
    "- https://danilzherebtsov.medium.com/tune-threshold-explained-with-code-b8098049c9ce"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cccd0647",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [0,0,0,0,0,0,0,0,1,1]\n",
    "probas = np.array([0.11, 0.05, 0.12, 0.02, 0.07, 0.14, 0.16, 0.11, 0.21, 0.24])\n",
    "\n",
    "# such probas will result in the predicted classes (with default 0.5 threshold) like below\n",
    "preds = np.array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5eb76311",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 0],\n",
       "       [2, 0]], dtype=int64)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       0.80      1.00      0.89         8\n",
      "     class 1       0.00      0.00      0.00         2\n",
      "\n",
      "    accuracy                           0.80        10\n",
      "   macro avg       0.40      0.50      0.44        10\n",
      "weighted avg       0.64      0.80      0.71        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "y_true = labels\n",
    "y_pred = preds\n",
    "confusion_matrix(y_true, y_pred)\n",
    "target_names = ['class 0', 'class 1']\n",
    "print(classification_report(y_true, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1adc3537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring based on default threshold\n",
      "--------------------------------------------------\n",
      "Accuracy score:          0.8\n",
      "Balanced accuracy score: 0.5\n",
      "F1 score:                0.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, balanced_accuracy_score, f1_score\n",
    "\n",
    "print('Scoring based on default threshold')\n",
    "print('-'*50)\n",
    "print(f'Accuracy score:          {accuracy_score(labels, probas > 0.5)}')\n",
    "print(f'Balanced accuracy score: {balanced_accuracy_score(labels, probas > 0.5)}')\n",
    "print(f'F1 score:                {f1_score(labels, probas > 0.5)}')\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9c5fa30c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our predicted probabilities are:\n",
      "[0.11 0.05 0.12 0.02 0.07 0.14 0.16 0.11 0.21 0.24]\n",
      "\n",
      "\n",
      "Find positive class with 0.5 threshold:\n",
      "[False False False False False False False False False False]\n"
     ]
    }
   ],
   "source": [
    "print('Our predicted probabilities are:')\n",
    "print(probas)\n",
    "print('\\n')\n",
    "print('Find positive class with 0.5 threshold:')\n",
    "print(probas>0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a0062a74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scoring based on tuned threshold\n",
      "--------------------------------------------------\n",
      "Accuracy score:          1.0\n",
      "Balanced accuracy score: 1.0\n",
      "F1 score:                1.0\n",
      "--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.17\n",
    "print('Scoring based on tuned threshold')\n",
    "print('-'*50)\n",
    "print(f'Accuracy score:          {accuracy_score(labels, probas > threshold)}')\n",
    "print(f'Balanced accuracy score: {balanced_accuracy_score(labels, probas > threshold)}')\n",
    "print(f'F1 score:                {f1_score(labels, probas > threshold)}')\n",
    "print('-'*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "412a8c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correct threshold application\n",
      "Labels fraction_of_1:      20.0%\n",
      "Predictions fraction_of_1: 20.0%\n",
      "------------------------------\n",
      "Incorrect threshold application\n",
      "Labels fraction_of_1:      20.0%\n",
      "Predictions fraction_of_1: 40.0% <-\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "correct_threshold = 0.17\n",
    "incorrect_threshold = 0.12\n",
    "\n",
    "print('Correct threshold application')\n",
    "print(f'Labels fraction_of_1:      {Counter(labels)[1] / len(labels)*100}%')\n",
    "print(f'Predictions fraction_of_1: {Counter(probas > correct_threshold)[1] / len(probas)*100}%')\n",
    "print('-'*30)\n",
    "print('Incorrect threshold application')\n",
    "print(f'Labels fraction_of_1:      {Counter(labels)[1] / len(labels)*100}%')\n",
    "print(f'Predictions fraction_of_1: {Counter(probas > incorrect_threshold)[1] / len(probas)*100}% <-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "61bf19f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 1, 1, 0, 1, 1])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds_012 = (probas > 0.12)*1\n",
    "preds_012"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f490ac72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 0],\n",
       "       [0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00         8\n",
      "     class 1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_017 = (probas > 0.17)*1\n",
    "confusion_matrix(y_true, preds_017)\n",
    "print(classification_report(y_true, preds_017, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd2135ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 0, 0, 0, 0, 0, 0, 0, 1, 1]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ThreshTuner(n_threshols = 20,            \n",
      "            min_threshold = None,                \n",
      "            max_threshold = None,                    \n",
      "            labels_fraction_of_1 = None,                        \n",
      "            loss_func = None\n",
      "\n",
      "                   Best threshold(s)\n",
      "-------------------------------------------------------\n",
      " threshold  balanced_accuracy_score  fraction_of_1\n",
      "  0.160000                      1.0            0.2\n",
      "  0.202105                      1.0            0.2\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from verstack import ThreshTuner\n",
    "labels\n",
    "thresh = ThreshTuner(n_thresholds = 20)\n",
    "thresh.fit(labels, probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f17c6d6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 0],\n",
       "       [0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00         8\n",
      "     class 1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_016 = (probas > 0.160000)*1\n",
    "confusion_matrix(y_true, preds_016)\n",
    "print(classification_report(y_true, preds_016, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65e611c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[8, 0],\n",
       "       [0, 2]], dtype=int64)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "     class 0       1.00      1.00      1.00         8\n",
      "     class 1       1.00      1.00      1.00         2\n",
      "\n",
      "    accuracy                           1.00        10\n",
      "   macro avg       1.00      1.00      1.00        10\n",
      "weighted avg       1.00      1.00      1.00        10\n",
      "\n"
     ]
    }
   ],
   "source": [
    "preds_017 = (probas > 0.202105)*1\n",
    "confusion_matrix(y_true, preds_017)\n",
    "print(classification_report(y_true, preds_017, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4a07dc07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import balanced_accuracy_score\n",
    "y_true = [0, 1, 0, 0, 1, 0]\n",
    "y_pred = [0, 1, 0, 0, 0, 1]\n",
    "balanced_accuracy_score(y_true, y_pred)\n",
    "accuracy_score(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e0223e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21332cdd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "boring-finger",
   "metadata": {},
   "source": [
    "### End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "elect-flashing",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
